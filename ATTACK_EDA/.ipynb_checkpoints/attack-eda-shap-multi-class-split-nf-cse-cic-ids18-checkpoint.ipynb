{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install fastAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (5.14.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly) (8.2.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from plotly) (23.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from fastcore.basics import *\n",
    "# from fastcore.parallel import *\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_score, recall_score, f1_score, accuracy_score\n",
    "from os import cpu_count\n",
    "from math import floor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# import shap\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "# shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=pd.read_parquet(\"/project_ghent/raman/netflow_datasets/nfcsecicids2018v2/NF-CSE-CIC-IDS2018-V2.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## very very Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.Attack.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ddos=data[data['Attack'].str.contains(\"ddos\",case=False)]\n",
    "dos=data[data['Attack'].str.contains(\"dos\",case=False)]\n",
    "data.drop(index=dos.index,inplace=True)\n",
    "dos.drop(index=ddos.index,inplace=True)\n",
    "\n",
    "brute=data[data['Attack'].str.contains(\"brute\",case=False)]\n",
    "data.drop(index=brute.index,inplace=True)\n",
    "\n",
    "print(\"before subsampling\")\n",
    "print(dos.Attack.value_counts())\n",
    "print(ddos.Attack.value_counts())\n",
    "print(brute.Attack.value_counts())\n",
    "\n",
    "grouped = dos.groupby(dos.Attack)\n",
    "dos_attacks=[ grouped.get_group(attack).sample(9512) for attack in dos.Attack.unique() ]\n",
    "dos=pd.concat(objs=dos_attacks)\n",
    "\n",
    "grouped = ddos.groupby(ddos.Attack)\n",
    "ddos_attacks=[ grouped.get_group(attack).sample(2112) for attack in ddos.Attack.unique() ]\n",
    "ddos=pd.concat(objs=ddos_attacks)\n",
    "\n",
    "grouped = brute.groupby(brute.Attack)\n",
    "brute_attacks=[ grouped.get_group(attack).sample(927) for attack in brute.Attack.unique() ]\n",
    "brute=pd.concat(objs=brute_attacks)\n",
    "\n",
    "\n",
    "print(\"after subsampling\")\n",
    "print(dos.Attack.value_counts())\n",
    "print(ddos.Attack.value_counts())\n",
    "print(brute.Attack.value_counts())\n",
    "\n",
    "dos.Attack=\"DoS\"\n",
    "ddos.Attack=\"DDoS\"\n",
    "brute.Attack=\"Brute Force\"\n",
    "data=pd.concat(objs=[data, dos,ddos,brute])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=data.drop(columns=['L4_SRC_PORT', 'L4_DST_PORT']) #dropping metadata\n",
    "data=data[data[\"Attack\"]!=\"Infilteration\"]\n",
    "# drop infiltration attacks because of inherently low classification score, results become less reliable when used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding contaminant features using XAI (SHAP)\n",
    "goal: \n",
    "- try to find the contaminant features that have blanked predictive power across all attack classes\n",
    "\n",
    "method:\n",
    "* look for shap values per feature that are consistantly high or low among all attack classes.\n",
    "   \n",
    "how:\n",
    "```\n",
    "possible_contaminants =[]\n",
    "    while models can achive high accuracy{\n",
    "    \n",
    "        * Train a binary classification model (e.g., xgboost) on different attack classes and benign class\n",
    "        * For each model, calculate shappley values on test set\n",
    "        * For each model, use np.abs(shap_values).mean(0) to compute the mean absolute SHAP value for each feature across all samples. \n",
    "          This will give you a measure of how much each feature contributes to the model output on average across all samples (the importance).\n",
    "          \n",
    "        * normalize importances across for each attack class sum of feature importances equals 1\n",
    "        * for each feature, calculate variance of importance for each attack class\n",
    "        * for each feature, calculate average importance across all attack classes\n",
    "        * score of a feature is the weighted sum of the importance and variance\n",
    "        \n",
    "        * feature F is feature with the highest score\n",
    "        * possible_contaminants.append(F)\n",
    "        * drop F from dataset\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set = data.sample(frac=0.3, replace=False,random_state=42)\n",
    "# 1%train, 99% test\n",
    "testing_set = data.drop(index=training_set.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.Attack.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attacks=training_set.Attack.unique()\n",
    "attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# corr = training_set.corr()\n",
    "# corr_features={corr.columns[i] : corr.columns[(corr>0.9).iloc[i]].values.tolist() for i in range(0,corr.shape[0])}\n",
    "# corr_list=[]\n",
    "# for key,value in corr_features.items():\n",
    "# #     check if we already have this set\n",
    "#     have_set=False\n",
    "#     for set_s in corr_list:\n",
    "#         if key in set_s:\n",
    "# #             we have found a set\n",
    "#             have_set=True\n",
    "#             break\n",
    "#     if have_set==False and len(value)>1:\n",
    "#         corr_list.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #dropping all but one feature per correlation group\n",
    "# for i in range(len(corr_list)):\n",
    "#     training_set.drop(columns=corr_list[i][1:],inplace=True)\n",
    "#     testing_set.drop(columns=corr_list[i][1:],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split into dataframes per attack class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grouped = training_set.groupby(training_set.Attack)\n",
    "dfs={cat:grouped.get_group(cat) for cat in attacks[1:]}\n",
    "dfs[attacks[0]]=grouped.get_group(attacks[0]) #don't subsample normal attacks\n",
    "#dfs key=attack_cat, value is dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for atk_type in attacks[1:]:\n",
    "    normals_to_sample = dfs[atk_type].shape[0]\n",
    "#     print(normals_to_sample)\n",
    "    normals_sample = dfs['Benign'].sample(normals_to_sample)\n",
    "#     dfs['Normal'] = dfs['Normal'].drop(index=normals_sample.index)#don't resample\n",
    "    dfs[atk_type] = pd.concat(objs=[dfs[atk_type], normals_sample])\n",
    "    print(dfs[atk_type].shape[0], normals_sample.shape[0], dfs['Benign'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing_dfs = {}\n",
    "grouped = testing_set.groupby(testing_set.Attack)\n",
    "testing_dfs={cat:grouped.get_group(cat) for cat in attacks[1:]}\n",
    "testing_dfs[attacks[0]]=grouped.get_group(attacks[0]) #don't subsample normal attacks\n",
    "#testing_dfs key=attack_cat, value is dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for atk_type in attacks[1:]:\n",
    "    normals_to_sample = testing_dfs[atk_type].shape[0] \n",
    "    normals_sample = testing_dfs['Benign'].sample(normals_to_sample)\n",
    "#     testing_dfs['Normal'] = testing_dfs['Normal'].drop(index=normals_sample.index)#don't resample\n",
    "    testing_dfs[atk_type] = pd.concat(objs=[testing_dfs[atk_type], normals_sample])\n",
    "    print(testing_dfs[atk_type].shape[0], normals_sample.shape[0], testing_dfs['Benign'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"TRAINING SETS\")\n",
    "for k,v in dfs.items():\n",
    "    v.drop(columns=['Attack'], inplace=True)   \n",
    "    print(k, v.shape)\n",
    "    print(v['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"TESTING SETS\")\n",
    "for k,v in testing_dfs.items():\n",
    "    v.drop(columns=['Attack'], inplace=True)   \n",
    "    print(k, v.shape)\n",
    "    print(v['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_dfs=dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L7_PROTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack]#[training_dfs[attack].ICMP_TYPE<=1000000]\n",
    "    k=d#[training_dfs[attack].Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 1000\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"L7_PROTO\"].max() - k[\"L7_PROTO\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='L7_PROTO',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.L7_PROTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k=training_set.L7_PROTO.astype(\"int64\").value_counts()\n",
    "print(k[k>10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['L7_PROTO'].apply(lambda x: ((x//1==0) | (x//1==5) | (x//1==91)).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### min_ttl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.histogram(training_set,x='MIN_TTL',color='Label',barmode='group',marginal='box',histnorm='percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['MIN_TTL'].apply(lambda x: ((x==63)|(x==128)|(x==127)).mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby([\"Label\",\"MIN_TTL\"]).MIN_TTL.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set[training_set.Attack=='DoS'].MIN_TTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TCP_WIN_MAX_IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],\n",
    "    x='TCP_WIN_MAX_IN',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['TCP_WIN_MAX_IN'].apply(lambda x: (x ==0).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TCP_WIN_MAX_OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],\n",
    "    x='TCP_WIN_MAX_OUT',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['TCP_WIN_MAX_OUT'].apply(lambda x: ((x==0)|(x==26883)|(x==26847)).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLOW_DURATION_MILLISECONDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],\n",
    "    x='FLOW_DURATION_MILLISECONDS',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['FLOW_DURATION_MILLISECONDS'].apply(lambda x: (x >4000000).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIN_TTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "px.histogram(training_set[training_set.Label==1],x='MIN_TTL',color='Label',barmode='group',marginal=\"box\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IN_BYTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack]#[training_dfs[attack].SRC_TO_DST_SECOND_BYTES<=1000000]\n",
    "    k=d#[training_dfs[attack].Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 500\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"IN_BYTES\"].max() - k[\"IN_BYTES\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='IN_BYTES',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['IN_BYTES'].apply(lambda x: (x>=500).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TCP_WIN_MAX_IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],\n",
    "    x='TCP_WIN_MAX_IN',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k=training_set.groupby([\"Label\",\"TCP_WIN_MAX_IN\"]).TCP_WIN_MAX_IN.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(k[k>30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['TCP_WIN_MAX_IN'].apply(lambda x: ((x==26883)).mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['TCP_WIN_MAX_IN'].apply(lambda x: ((x==0)|(x==8192)|(x==26883)|(x==65535)).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DURATION_OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],#[training_dfs[attack].Label>0],\n",
    "    x='DURATION_OUT',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['DURATION_OUT'].apply(lambda x: ((x!=0)).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUM_PKTS_128_TO_256_BYTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],#[training_dfs[attack].Label>0],\n",
    "    x='NUM_PKTS_128_TO_256_BYTES',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['NUM_PKTS_128_TO_256_BYTES'].apply(lambda x: ((x==0)|(x<=2)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TCP_FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],\n",
    "    x='TCP_FLAGS',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['TCP_FLAGS'].apply(lambda x: ((x==219)|(x==223)|(x==27)|(x==31)|(x==22)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LONGEST_FLOW_PKT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "#     d=training_dfs[attack][training_dfs[attack].DST_TO_SRC_SECOND_BYTES<=1000000]\n",
    "    k=training_dfs[attack]#[training_dfs[attack].Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 10\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"LONGEST_FLOW_PKT\"].max() - k[\"LONGEST_FLOW_PKT\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='LONGEST_FLOW_PKT',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k=training_set[training_set.Label==1].LONGEST_FLOW_PKT.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(k[k>10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['LONGEST_FLOW_PKT'].apply(lambda x: ((x==60)|(x==987)|(x==1024)|(x==366)|(x==975)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SRC_TO_DST_AVG_THROUGHPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack][training_dfs[attack].SRC_TO_DST_AVG_THROUGHPUT<=1000000]\n",
    "    k=d#[d.Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 100000\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"SRC_TO_DST_AVG_THROUGHPUT\"].max() - k[\"SRC_TO_DST_AVG_THROUGHPUT\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='SRC_TO_DST_AVG_THROUGHPUT',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['SRC_TO_DST_AVG_THROUGHPUT'].apply(lambda x: ((x<400000)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUT_BYTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack][training_dfs[attack].DST_TO_SRC_SECOND_BYTES<=1000000]\n",
    "    k=d#[d.Label==1]\n",
    "    bin_width= 100\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"OUT_BYTES\"].max() - k[\"OUT_BYTES\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='OUT_BYTES',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['OUT_BYTES'].apply(lambda x: ((x>175)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# k=training_set.groupby([\"Label\",\"OUT_BYTES\"]).OUT_BYTES.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(k[k>1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SRC_TO_DST_SECOND_BYTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack][training_dfs[attack].SRC_TO_DST_SECOND_BYTES<=1000000]\n",
    "    k=d#[training_dfs[attack].Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 100\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"SRC_TO_DST_SECOND_BYTES\"].max() - k[\"SRC_TO_DST_SECOND_BYTES\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='SRC_TO_DST_SECOND_BYTES',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['SRC_TO_DST_SECOND_BYTES'].apply(lambda x: ((x<=780)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DST_TO_SRC_SEOND+BYTES HIGH CORRELATION WITH ABOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack][training_dfs[attack].DST_TO_SRC_SECOND_BYTES<=1000000]\n",
    "    k=d#[d.Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 100\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"DST_TO_SRC_SECOND_BYTES\"].max() - k[\"DST_TO_SRC_SECOND_BYTES\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='DST_TO_SRC_SECOND_BYTES',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['DST_TO_SRC_SECOND_BYTES'].apply(lambda x: ((x>300)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DST_TO_SRC_AVG_THROUGHPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "#     d=training_dfs[attack][training_dfs[attack].DST_TO_SRC_SECOND_BYTES<=1000000]\n",
    "    k=training_dfs[attack]#[training_dfs[attack].Label==1]\n",
    "    k=k#[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 100000\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"DST_TO_SRC_AVG_THROUGHPUT\"].max() - k[\"DST_TO_SRC_AVG_THROUGHPUT\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='DST_TO_SRC_AVG_THROUGHPUT',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['DST_TO_SRC_AVG_THROUGHPUT'].apply(lambda x: ((x<1000000)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['DST_TO_SRC_AVG_THROUGHPUT'].apply(lambda x: ((x<1496000)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SERVER_TCP_FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack]#[training_dfs[attack].SRC_TO_DST_SECOND_BYTES<=1000000]\n",
    "    k=d#[training_dfs[attack].Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 100\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"SERVER_TCP_FLAGS\"].max() - k[\"SERVER_TCP_FLAGS\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='SERVER_TCP_FLAGS',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.corrcoef([training_set.SERVER_TCP_FLAGS,training_set.CLIENT_TCP_FLAGS,training_set.TCP_FLAGS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['SERVER_TCP_FLAGS'].apply(lambda x: ((x==27)|(x==20)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUM_PKTS_512_TO_1024_BYTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack]#[training_dfs[attack].NUM_PKTS_512_TO_1024_BYTES<=10000]\n",
    "    k=d[training_dfs[attack].Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 5\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"NUM_PKTS_512_TO_1024_BYTES\"].max() - k[\"NUM_PKTS_512_TO_1024_BYTES\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='NUM_PKTS_512_TO_1024_BYTES',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['NUM_PKTS_512_TO_1024_BYTES'].apply(lambda x: ((x>=1)).mean())*100).reset_index(name='Percentage')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUM_PKTS_256_TO_512_BYTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack]#[training_dfs[attack].NUM_PKTS_512_TO_1024_BYTES<=10000]\n",
    "    k=d[training_dfs[attack].Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 5\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"NUM_PKTS_256_TO_512_BYTES\"].max() - k[\"NUM_PKTS_256_TO_512_BYTES\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='NUM_PKTS_256_TO_512_BYTES',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['NUM_PKTS_256_TO_512_BYTES'].apply(lambda x: ((x<=1)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['NUM_PKTS_256_TO_512_BYTES'].apply(lambda x: ((x>=1)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHORTEST_FLOW_PKT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],\n",
    "    x='SHORTEST_FLOW_PKT',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['SHORTEST_FLOW_PKT'].apply(lambda x: ((x==40)|(x==52)|(x==60)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIN_IP_PKT_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],\n",
    "    x='MIN_IP_PKT_LEN',\n",
    "    color='Label',    barmode='group',\n",
    "\n",
    "    marginal='box',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['MIN_IP_PKT_LEN'].apply(lambda x: ((x==52)|(x==40)|(x==0)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICMP-TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack]#[training_dfs[attack].ICMP_TYPE<=1000000]\n",
    "    k=d[training_dfs[attack].Label==1]\n",
    "    k=k[k.ICMP_TYPE>0]\n",
    "    bin_width= 1000\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "#     nbins = math.ceil((k[\"ICMP_TYPE\"].max() - k[\"ICMP_TYPE\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='ICMP_TYPE',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['ICMP_TYPE'].apply(lambda x: ((x==0)|(x==0)|(x==0)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROTOCOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack]#[training_dfs[attack].ICMP_TYPE<=1000000]\n",
    "    k=d#[training_dfs[attack].Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 1000\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"PROTOCOL\"].max() - k[\"PROTOCOL\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='PROTOCOL',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['PROTOCOL'].apply(lambda x : ((x==6)|(x==17)).mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUM_PKTS_UP_TO_128_BYTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math \n",
    "for attack in attacks[1:]:\n",
    "#     d=training_dfs[attack][training_dfs[attack].DST_TO_SRC_SECOND_BYTES<=1000000]\n",
    "    k=training_dfs[attack]#[training_dfs[attack].Label==1]\n",
    "    k=k[k.NUM_PKTS_UP_TO_128_BYTES>0]\n",
    "    bin_width= 100\n",
    "#     here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"NUM_PKTS_UP_TO_128_BYTES\"].max() - k[\"NUM_PKTS_UP_TO_128_BYTES\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='NUM_PKTS_UP_TO_128_BYTES',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['NUM_PKTS_UP_TO_128_BYTES'].apply(lambda x: ((x==8)).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IN_PKTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "#     d=training_dfs[attack][training_dfs[attack].DST_TO_SRC_SECOND_BYTES<=1000000]\n",
    "    k=training_dfs[attack]#[training_dfs[attack].Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 2\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"IN_PKTS\"].max() - k[\"IN_PKTS\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='IN_PKTS',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['IN_PKTS'].apply(lambda x: ((x.between(0,4)) | (x.between(10,14))).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['IN_PKTS'].apply(lambda x: (x>4).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLIENT_TCP_FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],\n",
    "    x='CLIENT_TCP_FLAGS',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['CLIENT_TCP_FLAGS'].apply(lambda x: ((x.between(27,31))|(x.between(219,222))|(x ==30)).mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['CLIENT_TCP_FLAGS'].apply(lambda x: ((x ==219)|(x ==0)|(x ==219)).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLOW_DURATION_MILLISECONDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],\n",
    "    x='FLOW_DURATION_MILLISECONDS',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
