{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastAI in /opt/conda/lib/python3.10/site-packages (2.7.12)\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (from fastAI) (23.1.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from fastAI) (23.1)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from fastAI) (0.0.7)\n",
      "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /opt/conda/lib/python3.10/site-packages (from fastAI) (1.5.29)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.10/site-packages (from fastAI) (0.15.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from fastAI) (3.7.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from fastAI) (2.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from fastAI) (2.29.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from fastAI) (6.0)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.10/site-packages (from fastAI) (1.0.3)\n",
      "Requirement already satisfied: pillow>6.0.0 in /opt/conda/lib/python3.10/site-packages (from fastAI) (9.5.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from fastAI) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from fastAI) (1.10.1)\n",
      "Requirement already satisfied: spacy<4 in /opt/conda/lib/python3.10/site-packages (from fastAI) (3.5.2)\n",
      "Requirement already satisfied: torch<2.1,>=1.7 in /opt/conda/lib/python3.10/site-packages (from fastAI) (2.0.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastAI) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastAI) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastAI) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastAI) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastAI) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastAI) (8.1.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastAI) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastAI) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastAI) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastAI) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastAI) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastAI) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastAI) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastAI) (1.23.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastAI) (1.10.7)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastAI) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastAI) (67.7.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastAI) (3.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->fastAI) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->fastAI) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->fastAI) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->fastAI) (2022.12.7)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<2.1,>=1.7->fastAI) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch<2.1,>=1.7->fastAI) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<2.1,>=1.7->fastAI) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<2.1,>=1.7->fastAI) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch<2.1,>=1.7->fastAI) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch<2.1,>=1.7->fastAI) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.10/site-packages (from torch<2.1,>=1.7->fastAI) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch<2.1,>=1.7->fastAI) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch<2.1,>=1.7->fastAI) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch<2.1,>=1.7->fastAI) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.10/site-packages (from torch<2.1,>=1.7->fastAI) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.10/site-packages (from torch<2.1,>=1.7->fastAI) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.10/site-packages (from torch<2.1,>=1.7->fastAI) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.10/site-packages (from torch<2.1,>=1.7->fastAI) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.10/site-packages (from torch<2.1,>=1.7->fastAI) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch<2.1,>=1.7->fastAI) (2.0.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.1,>=1.7->fastAI) (0.40.0)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch<2.1,>=1.7->fastAI) (3.26.3)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch<2.1,>=1.7->fastAI) (16.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastAI) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastAI) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastAI) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastAI) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastAI) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastAI) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->fastAI) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->fastAI) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->fastAI) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->fastAI) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->fastAI) (1.16.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastAI) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastAI) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<4->fastAI) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<4->fastAI) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<2.1,>=1.7->fastAI) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install fastAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (5.14.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly) (8.2.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from plotly) (23.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.20.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from fastcore.basics import *\n",
    "# from fastcore.parallel import *\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_score, recall_score, f1_score, accuracy_score\n",
    "from os import cpu_count\n",
    "from math import floor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# import shap\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "# shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=pd.read_parquet(\"/project_ghent/raman/netflow_datasets/nfcsecicids2018v2/NF-CSE-CIC-IDS2018-V2.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## very very Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L4_SRC_PORT                      int32\n",
       "L4_DST_PORT                      int32\n",
       "PROTOCOL                          int8\n",
       "L7_PROTO                       float32\n",
       "IN_BYTES                         int32\n",
       "IN_PKTS                          int32\n",
       "OUT_BYTES                        int32\n",
       "OUT_PKTS                         int32\n",
       "TCP_FLAGS                        int16\n",
       "CLIENT_TCP_FLAGS                 int16\n",
       "SERVER_TCP_FLAGS                 int16\n",
       "FLOW_DURATION_MILLISECONDS       int32\n",
       "DURATION_IN                      int32\n",
       "DURATION_OUT                     int32\n",
       "MIN_TTL                          int16\n",
       "MAX_TTL                          int16\n",
       "LONGEST_FLOW_PKT                 int32\n",
       "SHORTEST_FLOW_PKT                int16\n",
       "MIN_IP_PKT_LEN                   int16\n",
       "MAX_IP_PKT_LEN                   int32\n",
       "SRC_TO_DST_SECOND_BYTES        float64\n",
       "DST_TO_SRC_SECOND_BYTES        float64\n",
       "RETRANSMITTED_IN_BYTES           int32\n",
       "RETRANSMITTED_IN_PKTS            int16\n",
       "RETRANSMITTED_OUT_BYTES          int32\n",
       "RETRANSMITTED_OUT_PKTS           int16\n",
       "SRC_TO_DST_AVG_THROUGHPUT        int64\n",
       "DST_TO_SRC_AVG_THROUGHPUT        int64\n",
       "NUM_PKTS_UP_TO_128_BYTES         int32\n",
       "NUM_PKTS_128_TO_256_BYTES        int16\n",
       "NUM_PKTS_256_TO_512_BYTES        int16\n",
       "NUM_PKTS_512_TO_1024_BYTES       int16\n",
       "NUM_PKTS_1024_TO_1514_BYTES      int32\n",
       "TCP_WIN_MAX_IN                   int32\n",
       "TCP_WIN_MAX_OUT                  int32\n",
       "ICMP_TYPE                        int32\n",
       "ICMP_IPV4_TYPE                   int16\n",
       "DNS_QUERY_ID                     int32\n",
       "DNS_QUERY_TYPE                   int16\n",
       "DNS_TTL_ANSWER                   int32\n",
       "FTP_COMMAND_RET_CODE              int8\n",
       "Label                             int8\n",
       "Attack                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    15101685\n",
       "1     2028030\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attack\n",
       "Benign                      15101685\n",
       "DDOS attack-HOIC             1066881\n",
       "DoS attacks-Hulk              432648\n",
       "DDoS attacks-LOIC-HTTP        207078\n",
       "Infilteration                 115513\n",
       "SSH-Bruteforce                 94979\n",
       "Bot                            28033\n",
       "DoS attacks-GoldenEye          27723\n",
       "FTP-BruteForce                 25933\n",
       "DoS attacks-SlowHTTPTest       14116\n",
       "DoS attacks-Slowloris           9512\n",
       "Brute Force -Web                2143\n",
       "DDOS attack-LOIC-UDP            2112\n",
       "Brute Force -XSS                 927\n",
       "SQL Injection                    432\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Attack.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1425/3256084828.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before subsampling\n",
      "Attack\n",
      "DoS attacks-Hulk            432648\n",
      "DoS attacks-GoldenEye        27723\n",
      "DoS attacks-SlowHTTPTest     14116\n",
      "DoS attacks-Slowloris         9512\n",
      "Name: count, dtype: int64\n",
      "Attack\n",
      "DDOS attack-HOIC          1066881\n",
      "DDoS attacks-LOIC-HTTP     207078\n",
      "DDOS attack-LOIC-UDP         2112\n",
      "Name: count, dtype: int64\n",
      "Attack\n",
      "SSH-Bruteforce      94979\n",
      "FTP-BruteForce      25933\n",
      "Brute Force -Web     2143\n",
      "Brute Force -XSS      927\n",
      "Name: count, dtype: int64\n",
      "after subsampling\n",
      "Attack\n",
      "DoS attacks-Slowloris       9512\n",
      "DoS attacks-Hulk            9512\n",
      "DoS attacks-GoldenEye       9512\n",
      "DoS attacks-SlowHTTPTest    9512\n",
      "Name: count, dtype: int64\n",
      "Attack\n",
      "DDoS attacks-LOIC-HTTP    2112\n",
      "DDOS attack-HOIC          2112\n",
      "DDOS attack-LOIC-UDP      2112\n",
      "Name: count, dtype: int64\n",
      "Attack\n",
      "SSH-Bruteforce      927\n",
      "FTP-BruteForce      927\n",
      "Brute Force -Web    927\n",
      "Brute Force -XSS    927\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ddos=data[data['Attack'].str.contains(\"ddos\",case=False)]\n",
    "dos=data[data['Attack'].str.contains(\"dos\",case=False)]\n",
    "data.drop(index=dos.index,inplace=True)\n",
    "dos.drop(index=ddos.index,inplace=True)\n",
    "\n",
    "brute=data[data['Attack'].str.contains(\"brute\",case=False)]\n",
    "data.drop(index=brute.index,inplace=True)\n",
    "\n",
    "print(\"before subsampling\")\n",
    "print(dos.Attack.value_counts())\n",
    "print(ddos.Attack.value_counts())\n",
    "print(brute.Attack.value_counts())\n",
    "\n",
    "grouped = dos.groupby(dos.Attack)\n",
    "dos_attacks=[ grouped.get_group(attack).sample(9512) for attack in dos.Attack.unique() ]\n",
    "dos=pd.concat(objs=dos_attacks)\n",
    "\n",
    "grouped = ddos.groupby(ddos.Attack)\n",
    "ddos_attacks=[ grouped.get_group(attack).sample(2112) for attack in ddos.Attack.unique() ]\n",
    "ddos=pd.concat(objs=ddos_attacks)\n",
    "\n",
    "grouped = brute.groupby(brute.Attack)\n",
    "brute_attacks=[ grouped.get_group(attack).sample(927) for attack in brute.Attack.unique() ]\n",
    "brute=pd.concat(objs=brute_attacks)\n",
    "\n",
    "\n",
    "print(\"after subsampling\")\n",
    "print(dos.Attack.value_counts())\n",
    "print(ddos.Attack.value_counts())\n",
    "print(brute.Attack.value_counts())\n",
    "\n",
    "dos.Attack=\"DoS\"\n",
    "ddos.Attack=\"DDoS\"\n",
    "brute.Attack=\"Brute Force\"\n",
    "data=pd.concat(objs=[data, dos,ddos,brute])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=data.drop(columns=['L4_SRC_PORT', 'L4_DST_PORT']) #dropping metadata\n",
    "data=data[data[\"Attack\"]!=\"Infilteration\"]\n",
    "# drop infiltration attacks because of inherently low classification score, results become less reliable when used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding contaminant features using XAI (SHAP)\n",
    "goal: \n",
    "- try to find the contaminant features that have blanked predictive power across all attack classes\n",
    "\n",
    "method:\n",
    "* look for shap values per feature that are consistantly high or low among all attack classes.\n",
    "   \n",
    "how:\n",
    "```\n",
    "possible_contaminants =[]\n",
    "    while models can achive high accuracy{\n",
    "    \n",
    "        * Train a binary classification model (e.g., xgboost) on different attack classes and benign class\n",
    "        * For each model, calculate shappley values on test set\n",
    "        * For each model, use np.abs(shap_values).mean(0) to compute the mean absolute SHAP value for each feature across all samples. \n",
    "          This will give you a measure of how much each feature contributes to the model output on average across all samples (the importance).\n",
    "          \n",
    "        * normalize importances across for each attack class sum of feature importances equals 1\n",
    "        * for each feature, calculate variance of importance for each attack class\n",
    "        * for each feature, calculate average importance across all attack classes\n",
    "        * score of a feature is the weighted sum of the importance and variance\n",
    "        \n",
    "        * feature F is feature with the highest score\n",
    "        * possible_contaminants.append(F)\n",
    "        * drop F from dataset\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set = data.sample(frac=0.3, replace=False,random_state=42)\n",
    "# 1%train, 99% test\n",
    "testing_set = data.drop(index=training_set.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attack\n",
       "Benign           4530478\n",
       "DoS                11340\n",
       "Bot                 8547\n",
       "DDoS                1915\n",
       "Brute Force         1078\n",
       "SQL Injection        115\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.Attack.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Benign', 'DoS', 'Bot', 'DDoS', 'SQL Injection', 'Brute Force'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacks=training_set.Attack.unique()\n",
    "attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# corr = training_set.corr()\n",
    "# corr_features={corr.columns[i] : corr.columns[(corr>0.9).iloc[i]].values.tolist() for i in range(0,corr.shape[0])}\n",
    "# corr_list=[]\n",
    "# for key,value in corr_features.items():\n",
    "# #     check if we already have this set\n",
    "#     have_set=False\n",
    "#     for set_s in corr_list:\n",
    "#         if key in set_s:\n",
    "# #             we have found a set\n",
    "#             have_set=True\n",
    "#             break\n",
    "#     if have_set==False and len(value)>1:\n",
    "#         corr_list.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #dropping all but one feature per correlation group\n",
    "# for i in range(len(corr_list)):\n",
    "#     training_set.drop(columns=corr_list[i][1:],inplace=True)\n",
    "#     testing_set.drop(columns=corr_list[i][1:],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split into dataframes per attack class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grouped = training_set.groupby(training_set.Attack)\n",
    "dfs={cat:grouped.get_group(cat) for cat in attacks[1:]}\n",
    "dfs[attacks[0]]=grouped.get_group(attacks[0]) #don't subsample normal attacks\n",
    "#dfs key=attack_cat, value is dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22680 11340 4530478\n",
      "17094 8547 4530478\n",
      "3830 1915 4530478\n",
      "230 115 4530478\n",
      "2156 1078 4530478\n"
     ]
    }
   ],
   "source": [
    "for atk_type in attacks[1:]:\n",
    "    normals_to_sample = dfs[atk_type].shape[0]\n",
    "#     print(normals_to_sample)\n",
    "    normals_sample = dfs['Benign'].sample(normals_to_sample)\n",
    "#     dfs['Normal'] = dfs['Normal'].drop(index=normals_sample.index)#don't resample\n",
    "    dfs[atk_type] = pd.concat(objs=[dfs[atk_type], normals_sample])\n",
    "    print(dfs[atk_type].shape[0], normals_sample.shape[0], dfs['Benign'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing_dfs = {}\n",
    "grouped = testing_set.groupby(testing_set.Attack)\n",
    "testing_dfs={cat:grouped.get_group(cat) for cat in attacks[1:]}\n",
    "testing_dfs[attacks[0]]=grouped.get_group(attacks[0]) #don't subsample normal attacks\n",
    "#testing_dfs key=attack_cat, value is dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53416 26708 10571207\n",
      "38972 19486 10571207\n",
      "8842 4421 10571207\n",
      "634 317 10571207\n",
      "5260 2630 10571207\n"
     ]
    }
   ],
   "source": [
    "for atk_type in attacks[1:]:\n",
    "    normals_to_sample = testing_dfs[atk_type].shape[0] \n",
    "    normals_sample = testing_dfs['Benign'].sample(normals_to_sample)\n",
    "#     testing_dfs['Normal'] = testing_dfs['Normal'].drop(index=normals_sample.index)#don't resample\n",
    "    testing_dfs[atk_type] = pd.concat(objs=[testing_dfs[atk_type], normals_sample])\n",
    "    print(testing_dfs[atk_type].shape[0], normals_sample.shape[0], testing_dfs['Benign'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SETS\n",
      "DoS (22680, 40)\n",
      "Label\n",
      "1    11340\n",
      "0    11340\n",
      "Name: count, dtype: int64\n",
      "Bot (17094, 40)\n",
      "Label\n",
      "1    8547\n",
      "0    8547\n",
      "Name: count, dtype: int64\n",
      "DDoS (3830, 40)\n",
      "Label\n",
      "1    1915\n",
      "0    1915\n",
      "Name: count, dtype: int64\n",
      "SQL Injection (230, 40)\n",
      "Label\n",
      "1    115\n",
      "0    115\n",
      "Name: count, dtype: int64\n",
      "Brute Force (2156, 40)\n",
      "Label\n",
      "1    1078\n",
      "0    1078\n",
      "Name: count, dtype: int64\n",
      "Benign (4530478, 40)\n",
      "Label\n",
      "0    4530478\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1425/520402162.py:3: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"TRAINING SETS\")\n",
    "for k,v in dfs.items():\n",
    "    v.drop(columns=['Attack'], inplace=True)   \n",
    "    print(k, v.shape)\n",
    "    print(v['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING SETS\n",
      "DoS (53416, 40)\n",
      "Label\n",
      "1    26708\n",
      "0    26708\n",
      "Name: count, dtype: int64\n",
      "Bot (38972, 40)\n",
      "Label\n",
      "1    19486\n",
      "0    19486\n",
      "Name: count, dtype: int64\n",
      "DDoS (8842, 40)\n",
      "Label\n",
      "1    4421\n",
      "0    4421\n",
      "Name: count, dtype: int64\n",
      "SQL Injection (634, 40)\n",
      "Label\n",
      "1    317\n",
      "0    317\n",
      "Name: count, dtype: int64\n",
      "Brute Force (5260, 40)\n",
      "Label\n",
      "1    2630\n",
      "0    2630\n",
      "Name: count, dtype: int64\n",
      "Benign (10571207, 40)\n",
      "Label\n",
      "0    10571207\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1425/4161559584.py:3: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TESTING SETS\")\n",
    "for k,v in testing_dfs.items():\n",
    "    v.drop(columns=['Attack'], inplace=True)   \n",
    "    print(k, v.shape)\n",
    "    print(v['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_dfs=dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### L7_PROTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack]#[training_dfs[attack].ICMP_TYPE<=1000000]\n",
    "    k=d#[training_dfs[attack].Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 1000\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"L7_PROTO\"].max() - k[\"L7_PROTO\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='L7_PROTO',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default='notebook'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.L7_PROTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k=training_set.L7_PROTO.astype(\"int64\").value_counts()\n",
    "print(k[k>10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['L7_PROTO'].apply(lambda x: ((x//1==0) | (x//1==5) | (x//1==91)).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### min_ttl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attack\n",
       "Benign            27.627791\n",
       "Bot              100.000000\n",
       "Brute Force       98.330241\n",
       "DDoS              99.112272\n",
       "DoS              100.000000\n",
       "SQL Injection    100.000000\n",
       "Name: MIN_TTL, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.groupby('Attack')['MIN_TTL'].apply(lambda x: ((x==63)|(x==128)|(x==127)).mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label  MIN_TTL\n",
       "0      0          1880831\n",
       "       1            29752\n",
       "       2               11\n",
       "       3                3\n",
       "       4              125\n",
       "                   ...   \n",
       "1      62              12\n",
       "       63           11882\n",
       "       64               3\n",
       "       127           2529\n",
       "       128           8549\n",
       "Name: MIN_TTL, Length: 157, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.groupby([\"Label\",\"MIN_TTL\"]).MIN_TTL.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set[training_set.Attack=='DoS'].MIN_TTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### TCP_WIN_MAX_IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],\n",
    "    x='TCP_WIN_MAX_IN',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['TCP_WIN_MAX_IN'].apply(lambda x: (x ==0).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### TCP_WIN_MAX_OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],\n",
    "    x='TCP_WIN_MAX_OUT',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['TCP_WIN_MAX_OUT'].apply(lambda x: ((x==0)|(x==26883)|(x==26847)).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### FLOW_DURATION_MILLISECONDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],\n",
    "    x='FLOW_DURATION_MILLISECONDS',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['FLOW_DURATION_MILLISECONDS'].apply(lambda x: (x >4000000).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### MIN_TTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "px.histogram(training_set[training_set.Label==1],x='MIN_TTL',color='Label',barmode='group',marginal=\"box\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### IN_BYTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack]#[training_dfs[attack].SRC_TO_DST_SECOND_BYTES<=1000000]\n",
    "    k=d#[training_dfs[attack].Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 500\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"IN_BYTES\"].max() - k[\"IN_BYTES\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='IN_BYTES',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['IN_BYTES'].apply(lambda x: (x>=500).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### TCP_WIN_MAX_IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],\n",
    "    x='TCP_WIN_MAX_IN',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k=training_set.groupby([\"Label\",\"TCP_WIN_MAX_IN\"]).TCP_WIN_MAX_IN.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(k[k>30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['TCP_WIN_MAX_IN'].apply(lambda x: ((x==26883)).mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['TCP_WIN_MAX_IN'].apply(lambda x: ((x==0)|(x==8192)|(x==26883)|(x==65535)).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### DURATION_OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],#[training_dfs[attack].Label>0],\n",
    "    x='DURATION_OUT',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['DURATION_OUT'].apply(lambda x: ((x!=0)).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### NUM_PKTS_128_TO_256_BYTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],#[training_dfs[attack].Label>0],\n",
    "    x='NUM_PKTS_128_TO_256_BYTES',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['NUM_PKTS_128_TO_256_BYTES'].apply(lambda x: ((x==0)|(x<=2)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### TCP_FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],\n",
    "    x='TCP_FLAGS',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['TCP_FLAGS'].apply(lambda x: ((x==219)|(x==223)|(x==27)|(x==31)|(x==22)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LONGEST_FLOW_PKT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "#     d=training_dfs[attack][training_dfs[attack].DST_TO_SRC_SECOND_BYTES<=1000000]\n",
    "    k=training_dfs[attack]#[training_dfs[attack].Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 10\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"LONGEST_FLOW_PKT\"].max() - k[\"LONGEST_FLOW_PKT\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='LONGEST_FLOW_PKT',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k=training_set[training_set.Label==1].LONGEST_FLOW_PKT.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(k[k>10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['LONGEST_FLOW_PKT'].apply(lambda x: ((x==60)|(x==987)|(x==1024)|(x==366)|(x==975)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SRC_TO_DST_AVG_THROUGHPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack][training_dfs[attack].SRC_TO_DST_AVG_THROUGHPUT<=1000000]\n",
    "    k=d#[d.Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 100000\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"SRC_TO_DST_AVG_THROUGHPUT\"].max() - k[\"SRC_TO_DST_AVG_THROUGHPUT\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='SRC_TO_DST_AVG_THROUGHPUT',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['SRC_TO_DST_AVG_THROUGHPUT'].apply(lambda x: ((x<400000)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUT_BYTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack][training_dfs[attack].DST_TO_SRC_SECOND_BYTES<=1000000]\n",
    "    k=d#[d.Label==1]\n",
    "    bin_width= 100\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"OUT_BYTES\"].max() - k[\"OUT_BYTES\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='OUT_BYTES',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['OUT_BYTES'].apply(lambda x: ((x>175)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# k=training_set.groupby([\"Label\",\"OUT_BYTES\"]).OUT_BYTES.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(k[k>1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SRC_TO_DST_SECOND_BYTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack][training_dfs[attack].SRC_TO_DST_SECOND_BYTES<=1000000]\n",
    "    k=d#[training_dfs[attack].Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 100\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"SRC_TO_DST_SECOND_BYTES\"].max() - k[\"SRC_TO_DST_SECOND_BYTES\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='SRC_TO_DST_SECOND_BYTES',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['SRC_TO_DST_SECOND_BYTES'].apply(lambda x: ((x<=780)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DST_TO_SRC_SEOND+BYTES HIGH CORRELATION WITH ABOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack][training_dfs[attack].DST_TO_SRC_SECOND_BYTES<=1000000]\n",
    "    k=d#[d.Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 100\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"DST_TO_SRC_SECOND_BYTES\"].max() - k[\"DST_TO_SRC_SECOND_BYTES\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='DST_TO_SRC_SECOND_BYTES',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['DST_TO_SRC_SECOND_BYTES'].apply(lambda x: ((x>300)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DST_TO_SRC_AVG_THROUGHPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "#     d=training_dfs[attack][training_dfs[attack].DST_TO_SRC_SECOND_BYTES<=1000000]\n",
    "    k=training_dfs[attack]#[training_dfs[attack].Label==1]\n",
    "    k=k#[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 100000\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"DST_TO_SRC_AVG_THROUGHPUT\"].max() - k[\"DST_TO_SRC_AVG_THROUGHPUT\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='DST_TO_SRC_AVG_THROUGHPUT',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['DST_TO_SRC_AVG_THROUGHPUT'].apply(lambda x: ((x<1000000)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['DST_TO_SRC_AVG_THROUGHPUT'].apply(lambda x: ((x<1496000)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SERVER_TCP_FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack]#[training_dfs[attack].SRC_TO_DST_SECOND_BYTES<=1000000]\n",
    "    k=d#[training_dfs[attack].Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 100\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"SERVER_TCP_FLAGS\"].max() - k[\"SERVER_TCP_FLAGS\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='SERVER_TCP_FLAGS',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.corrcoef([training_set.SERVER_TCP_FLAGS,training_set.CLIENT_TCP_FLAGS,training_set.TCP_FLAGS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['SERVER_TCP_FLAGS'].apply(lambda x: ((x==27)|(x==20)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUM_PKTS_512_TO_1024_BYTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack]#[training_dfs[attack].NUM_PKTS_512_TO_1024_BYTES<=10000]\n",
    "    k=d[training_dfs[attack].Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 5\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"NUM_PKTS_512_TO_1024_BYTES\"].max() - k[\"NUM_PKTS_512_TO_1024_BYTES\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='NUM_PKTS_512_TO_1024_BYTES',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['NUM_PKTS_512_TO_1024_BYTES'].apply(lambda x: ((x>=1)).mean())*100).reset_index(name='Percentage')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUM_PKTS_256_TO_512_BYTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack]#[training_dfs[attack].NUM_PKTS_512_TO_1024_BYTES<=10000]\n",
    "    k=d[training_dfs[attack].Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 5\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"NUM_PKTS_256_TO_512_BYTES\"].max() - k[\"NUM_PKTS_256_TO_512_BYTES\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='NUM_PKTS_256_TO_512_BYTES',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['NUM_PKTS_256_TO_512_BYTES'].apply(lambda x: ((x<=1)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['NUM_PKTS_256_TO_512_BYTES'].apply(lambda x: ((x>=1)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHORTEST_FLOW_PKT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],\n",
    "    x='SHORTEST_FLOW_PKT',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['SHORTEST_FLOW_PKT'].apply(lambda x: ((x==40)|(x==52)|(x==60)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIN_IP_PKT_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],\n",
    "    x='MIN_IP_PKT_LEN',\n",
    "    color='Label',    barmode='group',\n",
    "\n",
    "    marginal='box',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['MIN_IP_PKT_LEN'].apply(lambda x: ((x==52)|(x==40)|(x==0)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICMP-TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack]#[training_dfs[attack].ICMP_TYPE<=1000000]\n",
    "    k=d[training_dfs[attack].Label==1]\n",
    "    k=k[k.ICMP_TYPE>0]\n",
    "    bin_width= 1000\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "#     nbins = math.ceil((k[\"ICMP_TYPE\"].max() - k[\"ICMP_TYPE\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='ICMP_TYPE',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['ICMP_TYPE'].apply(lambda x: ((x==0)|(x==0)|(x==0)).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROTOCOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "    d=training_dfs[attack]#[training_dfs[attack].ICMP_TYPE<=1000000]\n",
    "    k=d#[training_dfs[attack].Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 1000\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"PROTOCOL\"].max() - k[\"PROTOCOL\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='PROTOCOL',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['PROTOCOL'].apply(lambda x : ((x==6)|(x==17)).mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUM_PKTS_UP_TO_128_BYTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math \n",
    "for attack in attacks[1:]:\n",
    "#     d=training_dfs[attack][training_dfs[attack].DST_TO_SRC_SECOND_BYTES<=1000000]\n",
    "    k=training_dfs[attack]#[training_dfs[attack].Label==1]\n",
    "    k=k[k.NUM_PKTS_UP_TO_128_BYTES>0]\n",
    "    bin_width= 100\n",
    "#     here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"NUM_PKTS_UP_TO_128_BYTES\"].max() - k[\"NUM_PKTS_UP_TO_128_BYTES\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='NUM_PKTS_UP_TO_128_BYTES',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['NUM_PKTS_UP_TO_128_BYTES'].apply(lambda x: ((x==8)).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IN_PKTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "for attack in attacks[1:]:\n",
    "#     d=training_dfs[attack][training_dfs[attack].DST_TO_SRC_SECOND_BYTES<=1000000]\n",
    "    k=training_dfs[attack]#[training_dfs[attack].Label==1]\n",
    "#     k=k[k.DST_TO_SRC_AVG_THROUGHPUT>0]\n",
    "    bin_width= 2\n",
    "    # here you can choose your rounding method, I've chosen math.ceil\n",
    "    nbins = math.ceil((k[\"IN_PKTS\"].max() - k[\"IN_PKTS\"].min()) / bin_width)\n",
    "    fig=px.histogram(\n",
    "    k,\n",
    "    x='IN_PKTS',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',#nbins=nbins,\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['IN_PKTS'].apply(lambda x: ((x.between(0,4)) | (x.between(10,14))).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(training_set.groupby('Attack')['IN_PKTS'].apply(lambda x: (x>4).mean())*100).reset_index(name='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLIENT_TCP_FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],\n",
    "    x='CLIENT_TCP_FLAGS',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['CLIENT_TCP_FLAGS'].apply(lambda x: ((x.between(27,31))|(x.between(219,222))|(x ==30)).mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.groupby('Attack')['CLIENT_TCP_FLAGS'].apply(lambda x: ((x ==219)|(x ==0)|(x ==219)).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLOW_DURATION_MILLISECONDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attack in attacks[1:]:\n",
    "    fig=px.histogram(\n",
    "    training_dfs[attack],\n",
    "    x='FLOW_DURATION_MILLISECONDS',\n",
    "    color='Label',\n",
    "    marginal='box',\n",
    "    barmode='group',\n",
    "    color_discrete_sequence=['turquoise','blue'],histnorm='percent',title=attack)\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
